Father of the digital age
he created many machines and was an inventor

he created [[Information Theory]]

he said that:
when something is extremely probable it should have little information when it is not probable it has a lot of information attached
Information = -Log2(*probability*)

Information entropy - the average of our information
the average information of our alphabet is 4.176 which is less than [[The Huffman code]]